@inproceedings{tsou2023wlst,
    abbr={arXiv},
    field={Vision},
    field_badge_class={badge_vision},
    abstract={In the field of domain adaptation (DA) on 3D object detection, most of the work is dedicated to unsupervised domain adaptation (UDA). Yet, without any target annotations, the performance gap between the UDA approaches and the fully-supervised approach is still noticeable, which is impractical for real-world applications. On the other hand, weakly-supervised domain adaptation (WDA) is an underexplored yet practical task that only requires few labeling effort on the target domain. To improve the DA performance in a cost-effective way, we propose a general weak labels guided self-training framework, WLST, designed for WDA on 3D object detection. By incorporating autolabeler, which can generate 3D pseudo labels from 2D bounding boxes, into the existing self-training pipeline, our method is able to generate more robust and consistent pseudo labels that would benefit the training process on the target domain. Extensive experiments demonstrate the effectiveness, robustness, and detector-agnosticism of our WLST framework. Notably, it outperforms previous state-of-the-art methods on all evaluation tasks.},
    title={WLST: Weak Labels Guided Self-training for Weakly-supervised Domain Adaptation on 3D Object Detection},
    author={Tsung-Lin Tsou and Tsung-Han Wu and Winston H. Hsu},
    booktitle={IEEE International Conference on Robotics and Automation (ICRA)},
    year={2024},
    arxiv={2310.03821},
    code={https://github.com/jacky121298/WLST},
    bibtex_show={true},
    selected={true},
}

@inproceedings{tsou2022deadlock,
    abbr={DATE},
    field={Automation},
    field_badge_class={badge_automation},
    abstract={We propose a Colored Timed Petri Net (CTPN) based model for intersection management. With the expressiveness of the CTPN-based model, we can consider timing, vehicle-specific information, and different types of vehicles. We then design deadlock-free policies and guarantee deadlock-freeness for intersection management. To the best of our knowledge, this is the first work on CTPN-based deadlock analysis and prevention for intersection management.},
    title={Deadlock Analysis and Prevention for Intersection Management Based on Colored Timed Petri Nets},
    author={Tsou, Tsung-Lin and Lin, Chung-Wei and Jiang, Iris Hui-Ru},
    booktitle={Design, Automation & Test in Europe Conference & Exhibition (DATE)},
    pages={124--127},
    year={2022},
    organization={IEEE},
    pdf={https://ieeexplore.ieee.org/document/9774773},
    code={https://github.com/jacky121298/Intersection_Management_CTPN},
    bibtex_show={true},
    selected={true},
}

@inproceedings{huang2021s3,
    abbr={CVPR},
    field={Vision},
    field_badge_class={badge_vision},
    abstract={Dense depth estimation plays a key role in multiple applications such as robotics, 3D reconstruction, and augmented reality. While sparse signal, e.g., LiDAR and Radar, has been leveraged as guidance for enhancing dense depth estimation, the improvement is limited due to its low density and imbalanced distribution. To maximize the utility from the sparse source, we propose S3 technique, which expands the depth value from sparse cues while estimating the confidence of expanded region. The proposed S3 can be applied to various guided depth estimation approaches and trained end-to-end at different stages, including input, cost volume and output. Extensive experiments demonstrate the effectiveness, robustness, and flexibility of the S3 technique on LiDAR and Radar signal.},
    title={S3: Learnable Sparse Signal Superdensity for Guided Depth Estimation},
    author={Huang, Yu-Kai and Liu, Yueh-Cheng and Wu, Tsung-Han and Su, Hung-Ting and Chang, Yu-Cheng and Tsou, Tsung-Lin and Wang, Yu-An and Hsu, Winston H},
    booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    pages={16706--16716},
    year={2021},
    arxiv={2103.02396},
    bibtex_show={true},
}